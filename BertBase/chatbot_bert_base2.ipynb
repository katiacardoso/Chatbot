{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementação Chatbot para respostas automatizadas com Bert Base"
      ],
      "metadata": {
        "id": "7l6HDQJocy5s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importação de bibliotecas"
      ],
      "metadata": {
        "id": "Vt-t7o93dHSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "# Registrar o tempo de início\n",
        "tempo_inicio = time.time()"
      ],
      "metadata": {
        "id": "iwraScjRlJ5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "YpoqWXI4yDgZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "302ac7bf-446c-432e-de85-aea8d0ce9ac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pO4qUpKDLci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "457a3d96-0b80-4485-bb0a-8463c9233acd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121\n",
            "Versão do Python 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "Versão do json: 2.0.9\n",
            "Versão do requests: 2.31.0\n",
            "Versão do numpy: 1.25.2\n",
            "Versão do pandas: 1.5.3\n",
            "Versão do torch: 2.1.0+cu121\n",
            "Versão do transformers: 4.38.1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "import requests\n",
        "from io import StringIO\n",
        "\n",
        "print(torch.__version__)\n",
        "\n",
        "import sys\n",
        "from transformers import __version__ as transformers_version\n",
        "import transformers as transformers\n",
        "\n",
        "print(\"Versão do Python\", sys.version)\n",
        "print(\"Versão do json:\", json.__version__)\n",
        "print(\"Versão do requests:\", requests.__version__)\n",
        "print(\"Versão do numpy:\", np.__version__)\n",
        "print(\"Versão do pandas:\", pd.__version__)\n",
        "print(\"Versão do torch:\", torch.__version__)\n",
        "print(\"Versão do transformers:\", transformers.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "i9RTIA7aVVA6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importação de dados"
      ],
      "metadata": {
        "id": "-2zuoVqZ-Yj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importação dos dados\n",
        "url = 'https://raw.githubusercontent.com/katiacardoso/EMAP_Chatbot/main/perguntas_respostass.csv'\n",
        "\n",
        "# Baixar o conteúdo do arquivo usando requests\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verificar se a requisição foi bem-sucedida\n",
        "if response.status_code == 200:\n",
        "    # Criar um objeto pandas DataFrame a partir do conteúdo baixado\n",
        "    df = pd.read_csv(StringIO(response.text), usecols=['Pergunta', 'Resposta'])\n",
        "    # Agora você pode usar o DataFrame 'data' normalmente\n",
        "else:\n",
        "    print(\"Falha ao baixar o arquivo. Código de status:\", response.status_code)\n",
        "\n",
        "\n",
        "df.to_csv('perguntas_respostass.csv', index=False)"
      ],
      "metadata": {
        "id": "-ULlqy_8GaSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Carregue o modelo BERT pré-treinado e o tokenizador\n",
        "model_name = \"bert-base-multilingual-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertModel.from_pretrained(model_name)\n",
        "\n"
      ],
      "metadata": {
        "id": "PrkD-0SNdR5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transformação em CSV"
      ],
      "metadata": {
        "id": "6fgfKswb-cKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Carregue o arquivo CSV com perguntas e respostas\n",
        "#df = pd.read_csv(\"perguntas_respostass.csv\")\n",
        "\n",
        "# Converter os dados para um formato adequado para JSON\n",
        "data = []\n",
        "for index, row in df.iterrows():\n",
        "    pergunta = row['Pergunta']\n",
        "    resposta = row['Resposta']\n",
        "    data.append({'pergunta': pergunta, 'resposta': resposta})\n",
        "\n",
        "\n",
        "# Salvar os dados como JSON em um arquivo\n",
        "with open('perguntas_respostas.json', 'w', encoding='utf-8') as json_file:\n",
        "    json.dump(data, json_file, ensure_ascii=False, indent=4)\n",
        "\n",
        "# Carregar dados do arquivo JSON\n",
        "with open('perguntas_respostas.json', 'r', encoding='utf-8') as json_file:\n",
        "    data = json.load(json_file)\n",
        "\n",
        "# Extrair perguntas e respostas\n",
        "perguntas = [qa['pergunta'] for qa in data]\n",
        "respostas = [qa['resposta'] for qa in data]"
      ],
      "metadata": {
        "id": "Cx0blEk0dWvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Vetorização"
      ],
      "metadata": {
        "id": "mvakujMDcFJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para vetorizar texto usando BERT\n",
        "def vetorizar_texto(texto):\n",
        "    inputs = tokenizer(texto, return_tensors='pt', padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    embeddings = torch.mean(outputs.last_hidden_state, dim=1)  # Média das embeddings das palavras\n",
        "    return embeddings\n",
        "\n",
        "# Vetorizar perguntas usando BERT\n",
        "perguntas_embeddings = torch.cat([vetorizar_texto(pergunta) for pergunta in perguntas])"
      ],
      "metadata": {
        "id": "W4kwnR4pb61L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perguntas_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loUZ8xs_q2Zx",
        "outputId": "69714816-f0f4-4866-b2ca-a373df16c895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([120, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testes de entendimento de codigo"
      ],
      "metadata": {
        "id": "D1ctwztB-H6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''# Print do número de perguntas vetorizadas\n",
        "print(len(perguntas_embeddings))\n",
        "\n",
        "# Imprimir as embeddings das perguntas\n",
        "#print(perguntas_embeddings)\n",
        "\n",
        "\n",
        "# Imprimir as embeddings das palavras individuais\n",
        "for i, pergunta in enumerate(perguntas):\n",
        "    print(\"Pergunta:\", pergunta)\n",
        "    print(\"Embeddings:\", perguntas_embeddings[i])\n",
        "\n",
        "# Selecionar uma pergunta específica\n",
        "#pergunta_selecionada = perguntas[0]\n",
        "pergunta_selecionada = 'como chegar ao Porto?'\n",
        "#pergunta_selecionada = input(\"Insira uma pergunta: \")\n",
        "\n",
        "# Vetorizar a pergunta selecionada\n",
        "pergunta_embeddings = vetorizar_texto(pergunta_selecionada)\n",
        "\n",
        "# Imprimir a pergunta selecionada\n",
        "print(pergunta_selecionada)\n",
        "\n",
        "# Imprimir as embeddings da pergunta selecionada\n",
        "#print(pergunta_embeddings)\n",
        "#neste codigo acima imprime um embedding gigante\n",
        "\n",
        "# Vetorizar as perguntas usando BERT\n",
        "perguntas_embeddings = torch.cat([vetorizar_texto(pergunta) for pergunta in pergunta_selecionada])\n",
        "\n",
        "# Imprimir as embeddings das perguntas\n",
        "print(perguntas_embeddings)'''\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svZzXr6wI7jd",
        "outputId": "3cdf8637-085a-4876-fb94-40e6057138ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# Print do número de perguntas vetorizadas\\nprint(len(perguntas_embeddings))\\n\\n# Imprimir as embeddings das perguntas\\n#print(perguntas_embeddings)\\n\\n\\n# Imprimir as embeddings das palavras individuais\\nfor i, pergunta in enumerate(perguntas):\\n    print(\"Pergunta:\", pergunta)\\n    print(\"Embeddings:\", perguntas_embeddings[i])\\n\\n# Selecionar uma pergunta específica\\n#pergunta_selecionada = perguntas[0]\\npergunta_selecionada = \\'como chegar ao Porto?\\'\\n#pergunta_selecionada = input(\"Insira uma pergunta: \")\\n\\n# Vetorizar a pergunta selecionada\\npergunta_embeddings = vetorizar_texto(pergunta_selecionada)\\n\\n# Imprimir a pergunta selecionada\\nprint(pergunta_selecionada)\\n\\n# Imprimir as embeddings da pergunta selecionada\\n#print(pergunta_embeddings)\\n#neste codigo acima imprime um embedding gigante\\n\\n# Vetorizar as perguntas usando BERT\\nperguntas_embeddings = torch.cat([vetorizar_texto(pergunta) for pergunta in pergunta_selecionada])\\n\\n# Imprimir as embeddings das perguntas\\nprint(perguntas_embeddings)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#tokenização"
      ],
      "metadata": {
        "id": "E_vyyb_Z-hI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(user_input, limiar_minimo=0.2):\n",
        "    user_input_embedding = vetorizar_texto(user_input)\n",
        "    similarity_scores = cosine_similarity(user_input_embedding, perguntas_embeddings)\n",
        "    average_similarity = similarity_scores.mean()\n",
        "\n",
        "    # Adicione um limiar de similaridade mínimo para classificar a resposta\n",
        "    if average_similarity > limiar_minimo:\n",
        "        best_match_index = similarity_scores.argmax()\n",
        "        resposta = respostas[best_match_index]\n",
        "    else:\n",
        "        resposta = \"Desculpe, não consegui encontrar uma correspondência adequada.\"\n",
        "\n",
        "    return resposta"
      ],
      "metadata": {
        "id": "81TA9MSddZjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para encontrar as melhores respostas com base na pergunta do usuário usando BERT\n",
        "def chatbot_verbose(user_input, limiar_minimo=0.7, top_n=5):\n",
        "    user_input_embedding = vetorizar_texto(user_input)\n",
        "    similarity_scores = cosine_similarity(user_input_embedding, perguntas_embeddings)\n",
        "    top_n_indices = similarity_scores.flatten().argsort()[-top_n:][::-1]\n",
        "\n",
        "    # Imprime as 5 perguntas mais similares e seus valores de similaridade\n",
        "    print(\"Top 5 Perguntas Mais Similares:\")\n",
        "    for i, index in enumerate(top_n_indices):\n",
        "        pergunta_similar = perguntas[index]\n",
        "        similaridade = similarity_scores[0, index]\n",
        "        print(f\"{i+1}. {pergunta_similar} - Similaridade: {similaridade}\")\n",
        "    # Adiciona um limiar de similaridade mínimo para classificar as respostas\n",
        "    if similarity_scores[0, top_n_indices[0]] > limiar_minimo:\n",
        "        best_match_index = top_n_indices[0]\n",
        "        pergunta_mais_similar = perguntas[best_match_index]\n",
        "        resposta_correspondente = respostas[best_match_index]\n",
        "        print(f\"\\nPergunta mais semelhante (índice {best_match_index}): {pergunta_mais_similar}\")\n",
        "        print(f\"Resposta correspondente: {resposta_correspondente}\")\n",
        "    else:\n",
        "        resposta_correspondente = \"Desculpe, não consegui encontrar uma correspondência adequada.\"\n",
        "        print(resposta_correspondente)\n",
        "\n",
        "    return resposta_correspondente\n",
        "\n",
        "\n",
        "\n",
        "# Pergunta do usuário\n",
        "user_question = \"Capitu traiu Bentinho?\"\n",
        "\n",
        "# Obtenha a resposta usando chatbot_verbose\n",
        "response = chatbot_verbose(user_question)\n",
        "\n",
        "# Imprima a resposta\n",
        "#print(\"Resposta do Chatbot:\", response)"
      ],
      "metadata": {
        "id": "iF7RqXfofiqF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d914c1ae-af15-47eb-a8eb-f0282dce1655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Perguntas Mais Similares:\n",
            "1. Como é o processo de seleção e entrevista para empregos no Porto do Itaqui? - Similaridade: 0.6952014565467834\n",
            "2. Como é o processo de seleção e entrevista para empregos no Porto do Itaqui? - Similaridade: 0.6952014565467834\n",
            "3. É necessário agendar previamente a visita ao Porto do Itaqui? - Similaridade: 0.6790130138397217\n",
            "4. Quais rodovias principais levam ao Porto do Itaqui? - Similaridade: 0.6641402244567871\n",
            "5. Como posso solicitar uma entrevista com representantes do Porto do Itaqui para minha reportagem? - Similaridade: 0.6601680517196655\n",
            "Desculpe, não consegui encontrar uma correspondência adequada.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pergunta \"Capitu traiu Bentinho\" teve maior similaridade com perguntas da base do  que \"Como chegar ao Porto\". Pergunta para uma próxima conversa com o João : Como delimitar que o chat responda apenas perguntas referentes aquele assunto?\n"
      ],
      "metadata": {
        "id": "JhRVV3KCM5NY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Calcular o tempo de execução\n",
        "tempo_execucao = time.time() - tempo_inicio\n",
        "print(\"Tempo de execução do chatbot: {:.2f} segundos\".format(tempo_execucao))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_p1aqWWlHg4",
        "outputId": "898b78df-9dee-4c99-d1d2-abaae63fab46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tempo de execução do chatbot: 45.22 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#simulaçao de conversa"
      ],
      "metadata": {
        "id": "0gx3g_PS-nZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista para armazenar as perguntas e respostas\n",
        "conversa = []\n",
        "\n",
        "# Inicie uma conversa com o chatbot\n",
        "while True:\n",
        "    user_input = input(\"Você: \")\n",
        "    if user_input.lower() == \"sair\":\n",
        "        print(\"Chatbot: Adeus! Até logo.\")\n",
        "        break\n",
        "    response = chatbot(user_input)\n",
        "    #response = chatbot(user_input)\n",
        "    print(\"Chatbot:\", response)\n",
        "\n",
        "    # Armazene a pergunta do usuário e a resposta do chatbot na lista\n",
        "    conversa.append({'pergunta': user_input, 'resposta': response})\n",
        "\n",
        "    # Salve a lista como JSON em um arquivo\n",
        "    with open('conversa.json', 'a', encoding='utf-8') as json_file:\n",
        "        json.dump(conversa, json_file, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "id": "eorBY1g0dcLQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01e22e4f-5fab-4ec5-b81c-2ef55e9cae93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Você: Como chegar no Porto?\n",
            "Chatbot: Confira aqui o mapa de localização e seja bem-vindo! http://www.portodoitaqui.ma.gov.br/porto-do-itaqui/como-chegar \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pergunta do usuário\n",
        "user_question = \"Como chegar no Porto\"\n",
        "\n",
        "# Obtenha a resposta usando chatbot_verbose\n",
        "response = chatbot_verbose(user_question)\n",
        "\n",
        "# Imprima a resposta\n",
        "print(\"Resposta do Chatbot:\", response)"
      ],
      "metadata": {
        "id": "a1U2Jf1Xf-T2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}